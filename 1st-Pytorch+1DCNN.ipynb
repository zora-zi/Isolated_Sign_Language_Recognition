{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4db13a43",
   "metadata": {
    "papermill": {
     "duration": 0.006373,
     "end_time": "2023-05-29T08:45:58.641495",
     "exception": false,
     "start_time": "2023-05-29T08:45:58.635122",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**NOTE: This submission utilizes the maximum inference time limit, so depending on the situation, a submission scoring error may occur. \n",
    "\n",
    "However, you can succeed by trying multiple times.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1fa2fda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-29T08:45:58.653542Z",
     "iopub.status.busy": "2023-05-29T08:45:58.652999Z",
     "iopub.status.idle": "2023-05-29T08:46:05.473598Z",
     "shell.execute_reply": "2023-05-29T08:46:05.472421Z"
    },
    "papermill": {
     "duration": 6.829986,
     "end_time": "2023-05-29T08:46:05.476585",
     "exception": false,
     "start_time": "2023-05-29T08:45:58.646599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "def read_json_file(file_path):\n",
    "    \"\"\"Read a JSON file and parse it into a Python object.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the JSON file to read.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary object representing the JSON data.\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundError: If the specified file path does not exist.\n",
    "        ValueError: If the specified file path does not contain valid JSON data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Open the file and load the JSON data into a Python object\n",
    "        with open(file_path, 'r') as file:\n",
    "            json_data = json.load(file)\n",
    "        return json_data\n",
    "    except FileNotFoundError:\n",
    "        # Raise an error if the file path does not exist\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "    except ValueError:\n",
    "        # Raise an error if the file does not contain valid JSON data\n",
    "        raise ValueError(f\"Invalid JSON data in file: {file_path}\")\n",
    "\n",
    "cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcdaec69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-29T08:46:05.488994Z",
     "iopub.status.busy": "2023-05-29T08:46:05.488321Z",
     "iopub.status.idle": "2023-05-29T08:46:05.746967Z",
     "shell.execute_reply": "2023-05-29T08:46:05.745651Z"
    },
    "papermill": {
     "duration": 0.26725,
     "end_time": "2023-05-29T08:46:05.749469",
     "exception": false,
     "start_time": "2023-05-29T08:46:05.482219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "... LOAD SIGN TO PREDICTION INDEX MAP FROM JSON FILE ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('/kaggle/input/asl-signs/train.csv')\n",
    "print(\"\\n\\n... LOAD SIGN TO PREDICTION INDEX MAP FROM JSON FILE ...\\n\")\n",
    "s2p_map = {k.lower():v for k,v in read_json_file(os.path.join(\"/kaggle/input/asl-signs/sign_to_prediction_index_map.json\")).items()}\n",
    "p2s_map = {v:k for k,v in read_json_file(os.path.join(\"/kaggle/input/asl-signs/sign_to_prediction_index_map.json\")).items()}\n",
    "encoder = lambda x: s2p_map.get(x.lower())\n",
    "decoder = lambda x: p2s_map.get(x)\n",
    "# print(s2p_map)\n",
    "train_df['label'] = train_df.sign.map(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3dc608d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-29T08:46:05.761839Z",
     "iopub.status.busy": "2023-05-29T08:46:05.761472Z",
     "iopub.status.idle": "2023-05-29T08:46:05.794233Z",
     "shell.execute_reply": "2023-05-29T08:46:05.792545Z"
    },
    "papermill": {
     "duration": 0.042083,
     "end_time": "2023-05-29T08:46:05.796759",
     "exception": false,
     "start_time": "2023-05-29T08:46:05.754676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n",
      "708\n"
     ]
    }
   ],
   "source": [
    "ROWS_PER_FRAME = 543\n",
    "MAX_LEN = 384\n",
    "CROP_LEN = MAX_LEN\n",
    "NUM_CLASSES  = 250\n",
    "PAD = -100.\n",
    "NOSE=[\n",
    "    1,2,98,327\n",
    "]\n",
    "LNOSE = [98]\n",
    "RNOSE = [327]\n",
    "LIP = [ 0, \n",
    "    61, 185, 40, 39, 37, 267, 269, 270, 409,\n",
    "    291, 146, 91, 181, 84, 17, 314, 405, 321, 375,\n",
    "    78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n",
    "    95, 88, 178, 87, 14, 317, 402, 318, 324, 308,\n",
    "]\n",
    "LLIP = [84,181,91,146,61,185,40,39,37,87,178,88,95,78,191,80,81,82]\n",
    "RLIP = [314,405,321,375,291,409,270,269,267,317,402,318,324,308,415,310,311,312]\n",
    "\n",
    "POSE = [500, 502, 504, 501, 503, 505, 512, 513]\n",
    "LPOSE = [513,505,503,501]\n",
    "RPOSE = [512,504,502,500]\n",
    "\n",
    "REYE = [\n",
    "    33, 7, 163, 144, 145, 153, 154, 155, 133,\n",
    "    246, 161, 160, 159, 158, 157, 173,\n",
    "]\n",
    "LEYE = [\n",
    "    263, 249, 390, 373, 374, 380, 381, 382, 362,\n",
    "    466, 388, 387, 386, 385, 384, 398,\n",
    "]\n",
    "\n",
    "LHAND = np.arange(468, 489).tolist()\n",
    "RHAND = np.arange(522, 543).tolist()\n",
    "\n",
    "POINT_LANDMARKS = LIP + LHAND + RHAND + NOSE + REYE + LEYE #+POSE\n",
    "\n",
    "NUM_NODES = len(POINT_LANDMARKS)\n",
    "CHANNELS = 6*NUM_NODES\n",
    "\n",
    "print(NUM_NODES)\n",
    "print(CHANNELS)\n",
    "\n",
    "def tf_nan_mean(x, axis=0, keepdims=False):\n",
    "    return tf.reduce_sum(tf.where(tf.math.is_nan(x), tf.zeros_like(x), x), axis=axis, keepdims=keepdims) / tf.reduce_sum(tf.where(tf.math.is_nan(x), tf.zeros_like(x), tf.ones_like(x)), axis=axis, keepdims=keepdims)\n",
    "\n",
    "def tf_nan_std(x, center=None, axis=0, keepdims=False):\n",
    "    if center is None:\n",
    "        center = tf_nan_mean(x, axis=axis,  keepdims=True)\n",
    "    d = x - center\n",
    "    return tf.math.sqrt(tf_nan_mean(d * d, axis=axis, keepdims=keepdims))\n",
    "\n",
    "class Preprocess(tf.keras.layers.Layer):\n",
    "    def __init__(self, max_len=MAX_LEN, point_landmarks=POINT_LANDMARKS, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.max_len = max_len\n",
    "        self.point_landmarks = point_landmarks\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if tf.rank(inputs) == 3:\n",
    "            x = inputs[None,...]\n",
    "        else:\n",
    "            x = inputs\n",
    "        \n",
    "        mean = tf_nan_mean(tf.gather(x, [17], axis=2), axis=[1,2], keepdims=True)\n",
    "        mean = tf.where(tf.math.is_nan(mean), tf.constant(0.5,x.dtype), mean)\n",
    "        x = tf.gather(x, self.point_landmarks, axis=2) #N,T,P,C\n",
    "        std = tf_nan_std(x, center=mean, axis=[1,2], keepdims=True)\n",
    "        \n",
    "        x = (x - mean)/std\n",
    "\n",
    "        if self.max_len is not None:\n",
    "            x = x[:,:self.max_len]\n",
    "        length = tf.shape(x)[1]\n",
    "        x = x[...,:2]\n",
    "\n",
    "        dx = tf.cond(tf.shape(x)[1]>1,lambda:tf.pad(x[:,1:] - x[:,:-1], [[0,0],[0,1],[0,0],[0,0]]),lambda:tf.zeros_like(x))\n",
    "\n",
    "        dx2 = tf.cond(tf.shape(x)[1]>2,lambda:tf.pad(x[:,2:] - x[:,:-2], [[0,0],[0,2],[0,0],[0,0]]),lambda:tf.zeros_like(x))\n",
    "\n",
    "        x = tf.concat([\n",
    "            tf.reshape(x, (-1,length,2*len(self.point_landmarks))),\n",
    "            tf.reshape(dx, (-1,length,2*len(self.point_landmarks))),\n",
    "            tf.reshape(dx2, (-1,length,2*len(self.point_landmarks))),\n",
    "        ], axis = -1)\n",
    "        \n",
    "        x = tf.where(tf.math.is_nan(x),tf.constant(0.,x.dtype),x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e31ec18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-29T08:46:05.808998Z",
     "iopub.status.busy": "2023-05-29T08:46:05.808709Z",
     "iopub.status.idle": "2023-05-29T08:46:05.834330Z",
     "shell.execute_reply": "2023-05-29T08:46:05.833191Z"
    },
    "papermill": {
     "duration": 0.034557,
     "end_time": "2023-05-29T08:46:05.836630",
     "exception": false,
     "start_time": "2023-05-29T08:46:05.802073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ECA(tf.keras.layers.Layer):\n",
    "    def __init__(self, kernel_size=5, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.kernel_size = kernel_size\n",
    "        self.conv = tf.keras.layers.Conv1D(1, kernel_size=kernel_size, strides=1, padding=\"same\", use_bias=False)\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        nn = tf.keras.layers.GlobalAveragePooling1D()(inputs, mask=mask)\n",
    "        nn = tf.expand_dims(nn, -1)\n",
    "        nn = self.conv(nn)\n",
    "        nn = tf.squeeze(nn, -1)\n",
    "        nn = tf.nn.sigmoid(nn)\n",
    "        nn = nn[:,None,:]\n",
    "        return inputs * nn\n",
    "\n",
    "class LateDropout(tf.keras.layers.Layer):\n",
    "    def __init__(self, rate, noise_shape=None, start_step=0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.rate = rate\n",
    "        self.start_step = start_step\n",
    "        self.dropout = tf.keras.layers.Dropout(rate, noise_shape=noise_shape)\n",
    "      \n",
    "    def build(self, input_shape):\n",
    "        super().build(input_shape)\n",
    "        agg = tf.VariableAggregation.ONLY_FIRST_REPLICA\n",
    "        self._train_counter = tf.Variable(0, dtype=\"int64\", aggregation=agg, trainable=False)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = tf.cond(self._train_counter < self.start_step, lambda:inputs, lambda:self.dropout(inputs, training=training))\n",
    "        if training:\n",
    "            self._train_counter.assign_add(1)\n",
    "        return x\n",
    "\n",
    "class CausalDWConv1D(tf.keras.layers.Layer):\n",
    "    def __init__(self, \n",
    "        kernel_size=17,\n",
    "        dilation_rate=1,\n",
    "        use_bias=False,\n",
    "        depthwise_initializer='glorot_uniform',\n",
    "        name='', **kwargs):\n",
    "        super().__init__(name=name,**kwargs)\n",
    "        self.causal_pad = tf.keras.layers.ZeroPadding1D((dilation_rate*(kernel_size-1),0),name=name + '_pad')\n",
    "        self.dw_conv = tf.keras.layers.DepthwiseConv1D(\n",
    "                            kernel_size,\n",
    "                            strides=1,\n",
    "                            dilation_rate=dilation_rate,\n",
    "                            padding='valid',\n",
    "                            use_bias=use_bias,\n",
    "                            depthwise_initializer=depthwise_initializer,\n",
    "                            name=name + '_dwconv')\n",
    "        self.supports_masking = True\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.causal_pad(inputs)\n",
    "        x = self.dw_conv(x)\n",
    "        return x\n",
    "\n",
    "def Conv1DBlock(channel_size,\n",
    "          kernel_size,\n",
    "          dilation_rate=1,\n",
    "          drop_rate=0.0,\n",
    "          expand_ratio=2,\n",
    "          se_ratio=0.25,\n",
    "          activation='swish',\n",
    "          name=None):\n",
    "    '''\n",
    "    efficient conv1d block, @hoyso48\n",
    "    '''\n",
    "    if name is None:\n",
    "        name = str(tf.keras.backend.get_uid(\"mbblock\"))\n",
    "    # Expansion phase\n",
    "    def apply(inputs):\n",
    "        channels_in = tf.keras.backend.int_shape(inputs)[-1]\n",
    "        channels_expand = channels_in * expand_ratio\n",
    "\n",
    "        skip = inputs\n",
    "\n",
    "        x = tf.keras.layers.Dense(\n",
    "            channels_expand,\n",
    "            use_bias=True,\n",
    "            activation=activation,\n",
    "            name=name + '_expand_conv')(inputs)\n",
    "\n",
    "        # Depthwise Convolution\n",
    "        x = CausalDWConv1D(kernel_size,\n",
    "            dilation_rate=dilation_rate,\n",
    "            use_bias=False,\n",
    "            name=name + '_dwconv')(x)\n",
    "\n",
    "        x = tf.keras.layers.BatchNormalization(momentum=0.95, name=name + '_bn')(x)\n",
    "\n",
    "        x  = ECA()(x)\n",
    "\n",
    "        x = tf.keras.layers.Dense(\n",
    "            channel_size,\n",
    "            use_bias=True,\n",
    "            name=name + '_project_conv')(x)\n",
    "\n",
    "        if drop_rate > 0:\n",
    "            x = tf.keras.layers.Dropout(drop_rate, noise_shape=(None,1,1), name=name + '_drop')(x)\n",
    "\n",
    "        if (channels_in == channel_size):\n",
    "            x = tf.keras.layers.add([x, skip], name=name + '_add')\n",
    "        return x\n",
    "\n",
    "    return apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65c38ca0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-29T08:46:05.849501Z",
     "iopub.status.busy": "2023-05-29T08:46:05.848533Z",
     "iopub.status.idle": "2023-05-29T08:46:05.867298Z",
     "shell.execute_reply": "2023-05-29T08:46:05.866387Z"
    },
    "papermill": {
     "duration": 0.027703,
     "end_time": "2023-05-29T08:46:05.869716",
     "exception": false,
     "start_time": "2023-05-29T08:46:05.842013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, dim=256, num_heads=4, dropout=0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dim = dim\n",
    "        self.scale = self.dim ** -0.5\n",
    "        self.num_heads = num_heads\n",
    "        self.qkv = tf.keras.layers.Dense(3 * dim, use_bias=False)\n",
    "        self.drop1 = tf.keras.layers.Dropout(dropout)\n",
    "        self.proj = tf.keras.layers.Dense(dim, use_bias=False)\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        qkv = self.qkv(inputs)\n",
    "        qkv = tf.keras.layers.Permute((2, 1, 3))(tf.keras.layers.Reshape((-1, self.num_heads, self.dim * 3 // self.num_heads))(qkv))\n",
    "        q, k, v = tf.split(qkv, [self.dim // self.num_heads] * 3, axis=-1)\n",
    "\n",
    "        attn = tf.matmul(q, k, transpose_b=True) * self.scale\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask[:, None, None, :]\n",
    "\n",
    "        attn = tf.keras.layers.Softmax(axis=-1)(attn, mask=mask)\n",
    "        attn = self.drop1(attn)\n",
    "\n",
    "        x = attn @ v\n",
    "        x = tf.keras.layers.Reshape((-1, self.dim))(tf.keras.layers.Permute((2, 1, 3))(x))\n",
    "        x = self.proj(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def TransformerBlock(dim=256, num_heads=4, expand=4, attn_dropout=0.2, drop_rate=0.2, activation='swish'):\n",
    "    def apply(inputs):\n",
    "        x = inputs\n",
    "        x = tf.keras.layers.BatchNormalization(momentum=0.95)(x)\n",
    "        x = MultiHeadSelfAttention(dim=dim,num_heads=num_heads,dropout=attn_dropout)(x)\n",
    "        x = tf.keras.layers.Dropout(drop_rate, noise_shape=(None,1,1))(x)\n",
    "        x = tf.keras.layers.Add()([inputs, x])\n",
    "        attn_out = x\n",
    "\n",
    "        x = tf.keras.layers.BatchNormalization(momentum=0.95)(x)\n",
    "        x = tf.keras.layers.Dense(dim*expand, use_bias=False, activation=activation)(x)\n",
    "        x = tf.keras.layers.Dense(dim, use_bias=False)(x)\n",
    "        x = tf.keras.layers.Dropout(drop_rate, noise_shape=(None,1,1))(x)\n",
    "        x = tf.keras.layers.Add()([attn_out, x])\n",
    "        return x\n",
    "    return apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3927be9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-29T08:46:05.881279Z",
     "iopub.status.busy": "2023-05-29T08:46:05.880942Z",
     "iopub.status.idle": "2023-05-29T08:46:05.894809Z",
     "shell.execute_reply": "2023-05-29T08:46:05.893723Z"
    },
    "papermill": {
     "duration": 0.022177,
     "end_time": "2023-05-29T08:46:05.897049",
     "exception": false,
     "start_time": "2023-05-29T08:46:05.874872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model(max_len=MAX_LEN, dropout_step=0, dim=192):\n",
    "    inp = tf.keras.Input((max_len,CHANNELS))\n",
    "    #x = tf.keras.layers.Masking(mask_value=PAD,input_shape=(max_len,CHANNELS))(inp) #we don't need masking layer with inference\n",
    "    x = inp\n",
    "    ksize = 17\n",
    "    x = tf.keras.layers.Dense(dim, use_bias=False,name='stem_conv')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(momentum=0.95,name='stem_bn')(x)\n",
    "\n",
    "    x = Conv1DBlock(dim,ksize,drop_rate=0.2)(x)\n",
    "    x = Conv1DBlock(dim,ksize,drop_rate=0.2)(x)\n",
    "    x = Conv1DBlock(dim,ksize,drop_rate=0.2)(x)\n",
    "    x = TransformerBlock(dim,expand=2)(x)\n",
    "\n",
    "    x = Conv1DBlock(dim,ksize,drop_rate=0.2)(x)\n",
    "    x = Conv1DBlock(dim,ksize,drop_rate=0.2)(x)\n",
    "    x = Conv1DBlock(dim,ksize,drop_rate=0.2)(x)\n",
    "    x = TransformerBlock(dim,expand=2)(x)\n",
    "\n",
    "    if dim == 384: #for the 4x sized model\n",
    "        x = Conv1DBlock(dim,ksize,drop_rate=0.2)(x)\n",
    "        x = Conv1DBlock(dim,ksize,drop_rate=0.2)(x)\n",
    "        x = Conv1DBlock(dim,ksize,drop_rate=0.2)(x)\n",
    "        x = TransformerBlock(dim,expand=2)(x)\n",
    "\n",
    "        x = Conv1DBlock(dim,ksize,drop_rate=0.2)(x)\n",
    "        x = Conv1DBlock(dim,ksize,drop_rate=0.2)(x)\n",
    "        x = Conv1DBlock(dim,ksize,drop_rate=0.2)(x)\n",
    "        x = TransformerBlock(dim,expand=2)(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(dim*2,activation=None,name='top_conv')(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "    x = LateDropout(0.8, start_step=dropout_step)(x)\n",
    "    x = tf.keras.layers.Dense(NUM_CLASSES,name='classifier')(x)\n",
    "    return tf.keras.Model(inp, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51d1c1d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-29T08:46:05.909518Z",
     "iopub.status.busy": "2023-05-29T08:46:05.908541Z",
     "iopub.status.idle": "2023-05-29T08:46:12.888528Z",
     "shell.execute_reply": "2023-05-29T08:46:12.887514Z"
    },
    "papermill": {
     "duration": 7.106902,
     "end_time": "2023-05-29T08:46:13.009415",
     "exception": false,
     "start_time": "2023-05-29T08:46:05.902513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 384, 708)]   0           []                               \n",
      "                                                                                                  \n",
      " stem_conv (Dense)              (None, 384, 192)     135936      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " stem_bn (BatchNormalization)   (None, 384, 192)     768         ['stem_conv[0][0]']              \n",
      "                                                                                                  \n",
      " 1_expand_conv (Dense)          (None, 384, 384)     74112       ['stem_bn[0][0]']                \n",
      "                                                                                                  \n",
      " 1_dwconv (CausalDWConv1D)      (None, 384, 384)     6528        ['1_expand_conv[0][0]']          \n",
      "                                                                                                  \n",
      " 1_bn (BatchNormalization)      (None, 384, 384)     1536        ['1_dwconv[0][0]']               \n",
      "                                                                                                  \n",
      " eca (ECA)                      (None, 384, 384)     5           ['1_bn[0][0]']                   \n",
      "                                                                                                  \n",
      " 1_project_conv (Dense)         (None, 384, 192)     73920       ['eca[0][0]']                    \n",
      "                                                                                                  \n",
      " 1_drop (Dropout)               (None, 384, 192)     0           ['1_project_conv[0][0]']         \n",
      "                                                                                                  \n",
      " 1_add (Add)                    (None, 384, 192)     0           ['1_drop[0][0]',                 \n",
      "                                                                  'stem_bn[0][0]']                \n",
      "                                                                                                  \n",
      " 2_expand_conv (Dense)          (None, 384, 384)     74112       ['1_add[0][0]']                  \n",
      "                                                                                                  \n",
      " 2_dwconv (CausalDWConv1D)      (None, 384, 384)     6528        ['2_expand_conv[0][0]']          \n",
      "                                                                                                  \n",
      " 2_bn (BatchNormalization)      (None, 384, 384)     1536        ['2_dwconv[0][0]']               \n",
      "                                                                                                  \n",
      " eca_1 (ECA)                    (None, 384, 384)     5           ['2_bn[0][0]']                   \n",
      "                                                                                                  \n",
      " 2_project_conv (Dense)         (None, 384, 192)     73920       ['eca_1[0][0]']                  \n",
      "                                                                                                  \n",
      " 2_drop (Dropout)               (None, 384, 192)     0           ['2_project_conv[0][0]']         \n",
      "                                                                                                  \n",
      " 2_add (Add)                    (None, 384, 192)     0           ['2_drop[0][0]',                 \n",
      "                                                                  '1_add[0][0]']                  \n",
      "                                                                                                  \n",
      " 3_expand_conv (Dense)          (None, 384, 384)     74112       ['2_add[0][0]']                  \n",
      "                                                                                                  \n",
      " 3_dwconv (CausalDWConv1D)      (None, 384, 384)     6528        ['3_expand_conv[0][0]']          \n",
      "                                                                                                  \n",
      " 3_bn (BatchNormalization)      (None, 384, 384)     1536        ['3_dwconv[0][0]']               \n",
      "                                                                                                  \n",
      " eca_2 (ECA)                    (None, 384, 384)     5           ['3_bn[0][0]']                   \n",
      "                                                                                                  \n",
      " 3_project_conv (Dense)         (None, 384, 192)     73920       ['eca_2[0][0]']                  \n",
      "                                                                                                  \n",
      " 3_drop (Dropout)               (None, 384, 192)     0           ['3_project_conv[0][0]']         \n",
      "                                                                                                  \n",
      " 3_add (Add)                    (None, 384, 192)     0           ['3_drop[0][0]',                 \n",
      "                                                                  '2_add[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 384, 192)    768         ['3_add[0][0]']                  \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " multi_head_self_attention (Mul  (None, 384, 192)    147456      ['batch_normalization[0][0]']    \n",
      " tiHeadSelfAttention)                                                                             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 384, 192)     0           ['multi_head_self_attention[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 384, 192)     0           ['3_add[0][0]',                  \n",
      "                                                                  'dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 384, 192)    768         ['add[0][0]']                    \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 384, 384)     73728       ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 384, 192)     73728       ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 384, 192)     0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 384, 192)     0           ['add[0][0]',                    \n",
      "                                                                  'dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " 4_expand_conv (Dense)          (None, 384, 384)     74112       ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " 4_dwconv (CausalDWConv1D)      (None, 384, 384)     6528        ['4_expand_conv[0][0]']          \n",
      "                                                                                                  \n",
      " 4_bn (BatchNormalization)      (None, 384, 384)     1536        ['4_dwconv[0][0]']               \n",
      "                                                                                                  \n",
      " eca_3 (ECA)                    (None, 384, 384)     5           ['4_bn[0][0]']                   \n",
      "                                                                                                  \n",
      " 4_project_conv (Dense)         (None, 384, 192)     73920       ['eca_3[0][0]']                  \n",
      "                                                                                                  \n",
      " 4_drop (Dropout)               (None, 384, 192)     0           ['4_project_conv[0][0]']         \n",
      "                                                                                                  \n",
      " 4_add (Add)                    (None, 384, 192)     0           ['4_drop[0][0]',                 \n",
      "                                                                  'add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " 5_expand_conv (Dense)          (None, 384, 384)     74112       ['4_add[0][0]']                  \n",
      "                                                                                                  \n",
      " 5_dwconv (CausalDWConv1D)      (None, 384, 384)     6528        ['5_expand_conv[0][0]']          \n",
      "                                                                                                  \n",
      " 5_bn (BatchNormalization)      (None, 384, 384)     1536        ['5_dwconv[0][0]']               \n",
      "                                                                                                  \n",
      " eca_4 (ECA)                    (None, 384, 384)     5           ['5_bn[0][0]']                   \n",
      "                                                                                                  \n",
      " 5_project_conv (Dense)         (None, 384, 192)     73920       ['eca_4[0][0]']                  \n",
      "                                                                                                  \n",
      " 5_drop (Dropout)               (None, 384, 192)     0           ['5_project_conv[0][0]']         \n",
      "                                                                                                  \n",
      " 5_add (Add)                    (None, 384, 192)     0           ['5_drop[0][0]',                 \n",
      "                                                                  '4_add[0][0]']                  \n",
      "                                                                                                  \n",
      " 6_expand_conv (Dense)          (None, 384, 384)     74112       ['5_add[0][0]']                  \n",
      "                                                                                                  \n",
      " 6_dwconv (CausalDWConv1D)      (None, 384, 384)     6528        ['6_expand_conv[0][0]']          \n",
      "                                                                                                  \n",
      " 6_bn (BatchNormalization)      (None, 384, 384)     1536        ['6_dwconv[0][0]']               \n",
      "                                                                                                  \n",
      " eca_5 (ECA)                    (None, 384, 384)     5           ['6_bn[0][0]']                   \n",
      "                                                                                                  \n",
      " 6_project_conv (Dense)         (None, 384, 192)     73920       ['eca_5[0][0]']                  \n",
      "                                                                                                  \n",
      " 6_drop (Dropout)               (None, 384, 192)     0           ['6_project_conv[0][0]']         \n",
      "                                                                                                  \n",
      " 6_add (Add)                    (None, 384, 192)     0           ['6_drop[0][0]',                 \n",
      "                                                                  '5_add[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 384, 192)    768         ['6_add[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_self_attention_1 (M  (None, 384, 192)    147456      ['batch_normalization_2[0][0]']  \n",
      " ultiHeadSelfAttention)                                                                           \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 384, 192)     0           ['multi_head_self_attention_1[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 384, 192)     0           ['6_add[0][0]',                  \n",
      "                                                                  'dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 384, 192)    768         ['add_2[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 384, 384)     73728       ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 384, 192)     73728       ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 384, 192)     0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 384, 192)     0           ['add_2[0][0]',                  \n",
      "                                                                  'dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " top_conv (Dense)               (None, 384, 384)     74112       ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 384)         0           ['top_conv[0][0]']               \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " late_dropout (LateDropout)     (None, 384)          1           ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " classifier (Dense)             (None, 250)          96250       ['late_dropout[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,836,569\n",
      "Trainable params: 1,830,040\n",
      "Non-trainable params: 6,529\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "models_path = [\n",
    "              '/kaggle/input/islr-models/islr-fp16-192-8-seed42-foldall-last.h5', #comment out other weights to check single model score\n",
    "               '/kaggle/input/islr-models/islr-fp16-192-8-seed43-foldall-last.h5',\n",
    "               '/kaggle/input/islr-models/islr-fp16-192-8-seed44-foldall-last.h5',\n",
    "               #'/kaggle/input/islr-models/islr-fp16-192-8-seed45-foldall-last.h5',\n",
    "              ]\n",
    "models = [get_model() for _ in models_path]\n",
    "for model,path in zip(models,models_path):\n",
    "    model.load_weights(path)\n",
    "models[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a62191f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-29T08:46:13.048874Z",
     "iopub.status.busy": "2023-05-29T08:46:13.048265Z",
     "iopub.status.idle": "2023-05-29T08:46:13.058011Z",
     "shell.execute_reply": "2023-05-29T08:46:13.056920Z"
    },
    "papermill": {
     "duration": 0.032179,
     "end_time": "2023-05-29T08:46:13.060482",
     "exception": false,
     "start_time": "2023-05-29T08:46:13.028303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TFLiteModel(tf.Module):\n",
    "    \"\"\"\n",
    "    TensorFlow Lite model that takes input tensors and applies:\n",
    "        – a preprocessing model\n",
    "        – the ISLR model \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, islr_models):\n",
    "        \"\"\"\n",
    "        Initializes the TFLiteModel with the specified preprocessing model and ISLR model.\n",
    "        \"\"\"\n",
    "        super(TFLiteModel, self).__init__()\n",
    "\n",
    "        # Load the feature generation and main models\n",
    "        self.prep_inputs = Preprocess()\n",
    "        self.islr_models   = islr_models\n",
    "    \n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=[None, 543, 3], dtype=tf.float32, name='inputs')])\n",
    "    def __call__(self, inputs):\n",
    "        \"\"\"\n",
    "        Applies the feature generation model and main model to the input tensors.\n",
    "\n",
    "        Args:\n",
    "            inputs: Input tensor with shape [batch_size, 543, 3].\n",
    "\n",
    "        Returns:\n",
    "            A dictionary with a single key 'outputs' and corresponding output tensor.\n",
    "        \"\"\"\n",
    "        x = self.prep_inputs(tf.cast(inputs, dtype=tf.float32))\n",
    "        outputs = [model(x) for model in self.islr_models]\n",
    "        outputs = tf.keras.layers.Average()(outputs)[0]\n",
    "        return {'outputs': outputs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2fd2136",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-29T08:46:13.097010Z",
     "iopub.status.busy": "2023-05-29T08:46:13.096709Z",
     "iopub.status.idle": "2023-05-29T08:46:13.103906Z",
     "shell.execute_reply": "2023-05-29T08:46:13.102944Z"
    },
    "papermill": {
     "duration": 0.028116,
     "end_time": "2023-05-29T08:46:13.106087",
     "exception": false,
     "start_time": "2023-05-29T08:46:13.077971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ROWS_PER_FRAME = 543  # number of landmarks per frame\n",
    "def load_relevant_data_subset(pq_path):\n",
    "    data_columns = ['x', 'y', 'z']\n",
    "    data = pd.read_parquet('/kaggle/input/asl-signs/' + pq_path, columns=data_columns)\n",
    "    n_frames = int(len(data) / ROWS_PER_FRAME)\n",
    "    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71ff6236",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-29T08:46:13.141906Z",
     "iopub.status.busy": "2023-05-29T08:46:13.140792Z",
     "iopub.status.idle": "2023-05-29T08:46:21.550792Z",
     "shell.execute_reply": "2023-05-29T08:46:21.549705Z"
    },
    "papermill": {
     "duration": 8.430643,
     "end_time": "2023-05-29T08:46:21.553684",
     "exception": false,
     "start_time": "2023-05-29T08:46:13.123041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blow'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_keras_model = TFLiteModel(islr_models=models)\n",
    "demo_output = tflite_keras_model(load_relevant_data_subset(train_df.path[0]))[\"outputs\"]\n",
    "decoder(np.argmax(demo_output.numpy(), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88a3419e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-29T08:46:21.590404Z",
     "iopub.status.busy": "2023-05-29T08:46:21.590036Z",
     "iopub.status.idle": "2023-05-29T08:47:44.349636Z",
     "shell.execute_reply": "2023-05-29T08:47:44.348110Z"
    },
    "papermill": {
     "duration": 82.781269,
     "end_time": "2023-05-29T08:47:44.352990",
     "exception": false,
     "start_time": "2023-05-29T08:46:21.571721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: kaggle/working/model.tflite (deflated 9%)\r\n"
     ]
    }
   ],
   "source": [
    "keras_model_converter = tf.lite.TFLiteConverter.from_keras_model(tflite_keras_model)\n",
    "keras_model_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "keras_model_converter.target_spec.supported_types = [tf.float16]\n",
    "tflite_model = keras_model_converter.convert()\n",
    "with open('/kaggle/working/model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "!zip submission.zip /kaggle/working/model.tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c00158b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-29T08:47:44.393234Z",
     "iopub.status.busy": "2023-05-29T08:47:44.392821Z",
     "iopub.status.idle": "2023-05-29T08:47:44.427470Z",
     "shell.execute_reply": "2023-05-29T08:47:44.426218Z"
    },
    "papermill": {
     "duration": 0.058261,
     "end_time": "2023-05-29T08:47:44.430029",
     "exception": false,
     "start_time": "2023-05-29T08:47:44.371768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import ok\n"
     ]
    }
   ],
   "source": [
    "#check inference time\n",
    "#code from @hengck23\n",
    "mode = 's' #'d'ebug #'s'ubmit\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "\n",
    "if mode in ['d']:  \n",
    "    try:\n",
    "        import tflite_runtime\n",
    "    except:\n",
    "        !pip install tflite-runtime\n",
    "\n",
    "    import tflite_runtime.interpreter as tflite   \n",
    "    import tflite_runtime\n",
    "    print(tflite_runtime.__version__)\n",
    "\n",
    "print('import ok')\n",
    "'''\n",
    "Your model must also require less than 40 MB in memory and \n",
    "perform inference with less than 100 milliseconds of latency per video. \n",
    "Expect to see approximately 40,000 videos in the test set. \n",
    "We allow an additional 10 minute buffer for loading the data and miscellaneous overhead.\n",
    "\n",
    "'''\n",
    "def time_to_str(t, mode='min'):\n",
    "    if mode=='min':\n",
    "        t  = int(t)/60\n",
    "        hr = t//60\n",
    "        min = t%60\n",
    "        return '%2d hr %02d min'%(hr,min)\n",
    "\n",
    "    elif mode=='sec':\n",
    "        t   = int(t)\n",
    "        min = t//60\n",
    "        sec = t%60\n",
    "        return '%2d min %02d sec'%(min,sec)\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "        \n",
    "ROWS_PER_FRAME = 543\n",
    "def load_relevant_data_subset(pq_path):\n",
    "    data_columns = ['x', 'y', 'z']\n",
    "    data = pd.read_parquet(pq_path, columns=data_columns)\n",
    "    n_frames = int(len(data) / ROWS_PER_FRAME)\n",
    "    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n",
    "    return data.astype(np.float32)\n",
    "\n",
    "if mode in ['d']: \n",
    " \n",
    "    interpreter = tflite.Interpreter('/kaggle/working/model.tflite')\n",
    "    prediction_fn = interpreter.get_signature_runner('serving_default')\n",
    "#     valid_df = pd.read_csv('/kaggle/input/asl-demo/train_prepared.csv') \n",
    "#     valid_df = train_df[train_df.fold==0].reset_index(drop=True)\n",
    "#     valid_df = valid_df[:1000]\n",
    "    valid_df = train_df[:1000]\n",
    "    valid_num = len(valid_df)\n",
    "    valid = {\n",
    "        'sign':[],\n",
    "    }\n",
    "\n",
    "    start_timer = timer()\n",
    "    for t, d in valid_df.iterrows():\n",
    "\n",
    "        pq_file = f'/kaggle/input/asl-signs/{d.path}'\n",
    "        #print(pq_file)\n",
    "        xyz = load_relevant_data_subset(pq_file)\n",
    "\n",
    "        output = prediction_fn(inputs=xyz)\n",
    "        p = output['outputs'].reshape(-1)\n",
    "\n",
    "        valid['sign'].append(p)\n",
    "\n",
    "        #---\n",
    "        if t%100==0:\n",
    "            time_taken = timer() - start_timer\n",
    "            print('\\r %8d / %d  %s'%(t,valid_num,time_to_str(time_taken,'sec')),end='',flush=True)\n",
    "\n",
    "    print('\\n')\n",
    "\n",
    "\n",
    "    truth = valid_df.label.values\n",
    "    sign  = np.stack(valid['sign'])\n",
    "    predict = np.argsort(-sign, -1)\n",
    "    correct = predict==truth.reshape(valid_num,1)\n",
    "    topk = correct.cumsum(-1).mean(0)[:5]\n",
    "\n",
    "\n",
    "    print(f'time_taken = {time_to_str(time_taken,\"sec\")}')\n",
    "    print(f'time_taken for LB = {time_taken*1000/valid_num:05f} msec\\n')\n",
    "    for i in range(5):\n",
    "        print(f'topk[{i}] = {topk[i]}')  \n",
    "    print('----- end -----\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647b7471",
   "metadata": {
    "papermill": {
     "duration": 0.018161,
     "end_time": "2023-05-29T08:47:44.465963",
     "exception": false,
     "start_time": "2023-05-29T08:47:44.447802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 119.943167,
   "end_time": "2023-05-29T08:47:48.145081",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-29T08:45:48.201914",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
