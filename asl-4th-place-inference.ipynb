{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8edce371",
   "metadata": {
    "papermill": {
     "duration": 0.006297,
     "end_time": "2023-05-05T15:03:13.116956",
     "exception": false,
     "start_time": "2023-05-05T15:03:13.110659",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### This code is a Google - Isolated Sign Language Recognition 4th place inferrence code.   \n",
    "\n",
    "+ Reads pre-trained models and creates tflite.\n",
    "+ Note: The model in the final submission is an ensemble of six. \n",
    "+ However, due to many cases of timeouts, this code restricted to 5 models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9761db5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T15:03:13.128896Z",
     "iopub.status.busy": "2023-05-05T15:03:13.128230Z",
     "iopub.status.idle": "2023-05-05T15:03:37.459893Z",
     "shell.execute_reply": "2023-05-05T15:03:37.458399Z"
    },
    "papermill": {
     "duration": 24.341259,
     "end_time": "2023-05-05T15:03:37.463151",
     "exception": false,
     "start_time": "2023-05-05T15:03:13.121892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tflite-runtime\r\n",
      "  Downloading tflite_runtime-2.11.0-cp37-cp37m-manylinux2014_x86_64.whl (2.5 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.19.2 in /opt/conda/lib/python3.7/site-packages (from tflite-runtime) (1.21.6)\r\n",
      "Installing collected packages: tflite-runtime\r\n",
      "Successfully installed tflite-runtime-2.11.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mCollecting onnx_tf\r\n",
      "  Downloading onnx_tf-1.10.0-py3-none-any.whl (226 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.1/226.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from onnx_tf) (6.0)\r\n",
      "Requirement already satisfied: onnx>=1.10.2 in /opt/conda/lib/python3.7/site-packages (from onnx_tf) (1.13.1)\r\n",
      "Requirement already satisfied: tensorflow-addons in /opt/conda/lib/python3.7/site-packages (from onnx_tf) (0.19.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /opt/conda/lib/python3.7/site-packages (from onnx>=1.10.2->onnx_tf) (4.4.0)\r\n",
      "Requirement already satisfied: protobuf<4,>=3.20.2 in /opt/conda/lib/python3.7/site-packages (from onnx>=1.10.2->onnx_tf) (3.20.3)\r\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.7/site-packages (from onnx>=1.10.2->onnx_tf) (1.21.6)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from tensorflow-addons->onnx_tf) (23.0)\r\n",
      "Requirement already satisfied: typeguard>=2.7 in /opt/conda/lib/python3.7/site-packages (from tensorflow-addons->onnx_tf) (2.13.3)\r\n",
      "Installing collected packages: onnx_tf\r\n",
      "Successfully installed onnx_tf-1.10.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tflite-runtime\n",
    "!pip install onnx_tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b7acee0",
   "metadata": {
    "papermill": {
     "duration": 0.00519,
     "end_time": "2023-05-05T15:03:37.474212",
     "exception": false,
     "start_time": "2023-05-05T15:03:37.469022",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6fde9c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T15:03:37.487644Z",
     "iopub.status.busy": "2023-05-05T15:03:37.487241Z",
     "iopub.status.idle": "2023-05-05T15:03:51.808966Z",
     "shell.execute_reply": "2023-05-05T15:03:51.807701Z"
    },
    "papermill": {
     "duration": 14.332316,
     "end_time": "2023-05-05T15:03:51.811928",
     "exception": false,
     "start_time": "2023-05-05T15:03:37.479612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import onnx_tf\n",
    "import onnx\n",
    "import tflite_runtime\n",
    "import tflite_runtime.interpreter\n",
    "\n",
    "from torchvision.ops import StochasticDepth\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0fb2ae3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T15:03:51.826396Z",
     "iopub.status.busy": "2023-05-05T15:03:51.825581Z",
     "iopub.status.idle": "2023-05-05T15:03:52.115373Z",
     "shell.execute_reply": "2023-05-05T15:03:52.114064Z"
    },
    "papermill": {
     "duration": 0.300507,
     "end_time": "2023-05-05T15:03:52.118203",
     "exception": false,
     "start_time": "2023-05-05T15:03:51.817696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class ArcMarginProduct(nn.Module):\n",
    "    def __init__(self, in_features, out_features, s=30.0, m=0.5, easy_margin=False):\n",
    "        super(ArcMarginProduct, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.weight = torch.nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.th = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "\n",
    "    def forward(self, x, label=None):\n",
    "        cosine = torch.nn.functional.linear(torch.nn.functional.normalize(\n",
    "            x), torch.nn.functional.normalize(self.weight)).float()\n",
    "        sine = torch.sqrt((1.0 - torch.pow(cosine, 2)).clamp(0, 1))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "\n",
    "        if label is None:\n",
    "            output = cosine\n",
    "        else:\n",
    "            one_hot = torch.zeros(cosine.size(), device='cuda')\n",
    "            one_hot.scatter_(1, label.cuda().view(-1, 1).long(), 1)\n",
    "            # you can use torch.where if your torch.__version__ is 0.4\n",
    "            output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class LRUnit1D(nn.Module):\n",
    "    def __init__(self, in_dim, stochastic_depth_prob=0.0, actf=torch.nn.ReLU()):\n",
    "        super(LRUnit1D, self).__init__()\n",
    "        self.layer0 = nn.Linear(in_dim, in_dim, bias=False)\n",
    "        self.bn0 = nn.BatchNorm1d(in_dim)\n",
    "        self.layer1 = nn.Linear(in_dim, in_dim, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(in_dim)\n",
    "        self.actf = actf\n",
    "        self.stochastic_depth = StochasticDepth(stochastic_depth_prob, \"row\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.actf(self.bn0(self.layer0(x)))\n",
    "        h = self.bn1(self.layer1(h))\n",
    "        h = self.stochastic_depth(h)\n",
    "        return x + h\n",
    "\n",
    "\n",
    "class RSUnit1D(nn.Module):\n",
    "    def __init__(self, in_dim, kernel_size=3, padding=1,\n",
    "                 padding_mode='zeros', actf=torch.nn.ReLU()):\n",
    "        super(RSUnit1D, self).__init__()\n",
    "        self.layer0 = nn.Conv1d(in_dim, in_dim, kernel_size=kernel_size, padding=padding, padding_mode=padding_mode, bias=False)\n",
    "        self.bn0 = nn.BatchNorm1d(in_dim)\n",
    "        self.layer1 = nn.Conv1d(in_dim, in_dim, kernel_size=kernel_size, padding=padding, padding_mode=padding_mode, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(in_dim)\n",
    "        self.actf = actf\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.actf(self.bn0(self.layer0(x)))\n",
    "        h = self.bn1(self.layer1(h))\n",
    "        return x + h\n",
    "\n",
    "\n",
    "\n",
    "class BackboneVariableLen(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_dim=42,\n",
    "                 dim1=128,\n",
    "                 dim2=512,\n",
    "                 kernel_size=3, padding=1,\n",
    "                 negative_slope=0.1,\n",
    "                 ):\n",
    "        super(BackboneVariableLen, self).__init__()\n",
    "        self.actf = torch.nn.LeakyReLU(negative_slope=negative_slope)\n",
    "        self.bn0 = nn.BatchNorm1d(in_dim)\n",
    "        self.conv1 = nn.Conv1d(in_dim, dim1, kernel_size=kernel_size, padding=padding, bias=True)\n",
    "        self.conv2 = RSUnit1D(dim1, kernel_size=kernel_size, padding=padding, actf=self.actf)\n",
    "        self.conv3 = RSUnit1D(dim1, kernel_size=kernel_size, padding=padding, actf=self.actf)\n",
    "        self.conv4 = RSUnit1D(dim1, kernel_size=1, padding=0, actf=self.actf)\n",
    "        self.conv5 = RSUnit1D(dim1, kernel_size=1, padding=0, actf=self.actf)\n",
    "        self.conv6 = RSUnit1D(dim1, kernel_size=1, padding=0, actf=self.actf)\n",
    "        self.conv6a = nn.Conv1d(dim1, dim2, kernel_size=1, padding=0, bias=True)\n",
    "\n",
    "        self.flatten = torch.nn.Flatten(1)\n",
    "        self.g_pool = torch.nn.AdaptiveMaxPool1d(1, return_indices=False)\n",
    "        self.pool = torch.nn.MaxPool1d(2)\n",
    "\n",
    "    def forward(self, h):\n",
    "        h = self.bn0(h)\n",
    "        h = self.conv1(h)\n",
    "        h = self.conv2(h)\n",
    "        h = self.conv3(h)\n",
    "        h = self.conv4(h)\n",
    "        h = self.conv5(h)\n",
    "        h = self.conv6(h)\n",
    "        h = self.conv6a(h)\n",
    "        print(h.shape)\n",
    "\n",
    "        # Remove padding to match during trainning\n",
    "        h = h[:, :, :-5]\n",
    "\n",
    "        print(h.shape)\n",
    "        h = self.g_pool(h)\n",
    "        h = self.flatten(h)\n",
    "        return h\n",
    "\n",
    "\n",
    "class ModelVariableLen(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_dim_H=42,\n",
    "                 in_dim_L=80,\n",
    "                 dim1_H=128,\n",
    "                 dim1_L=64,\n",
    "                 dim2=512,\n",
    "                 n_class=250,\n",
    "                 kernel_size=3, padding=1,\n",
    "                 arc_m=0.5,\n",
    "                 arc_s=15,\n",
    "                 easy_margin=False,\n",
    "                 stochastic_depth_prob=0.0,\n",
    "                 negative_slope=0.1,\n",
    "                 n_recyile=1\n",
    "                 ):\n",
    "        super(ModelVariableLen, self).__init__()\n",
    "        self.actf = torch.nn.LeakyReLU(negative_slope=negative_slope)\n",
    "        self.hand_module = BackboneVariableLen(in_dim=in_dim_H, dim1=dim1_H, dim2=dim2, negative_slope=negative_slope)\n",
    "        self.other_module = BackboneVariableLen(in_dim=in_dim_L, dim1=dim1_L, dim2=dim2, negative_slope=negative_slope)\n",
    "\n",
    "        self.line1 = LRUnit1D(dim2, stochastic_depth_prob, actf=self.actf)\n",
    "        self.line2 = LRUnit1D(dim2, stochastic_depth_prob, actf=self.actf)\n",
    "        self.line3 = LRUnit1D(dim2, stochastic_depth_prob, actf=self.actf)\n",
    "        self.end = ArcMarginProduct(dim2, n_class, easy_margin=easy_margin, s=arc_s, m=arc_m)\n",
    "        self.flatten = torch.nn.Flatten(1)\n",
    "        self.g_pool = torch.nn.AdaptiveMaxPool1d(1, return_indices=False)\n",
    "        self.pool = torch.nn.MaxPool1d(2)\n",
    "\n",
    "        self.n_recyile = n_recyile\n",
    "\n",
    "    def forward(self, hand, other):\n",
    "        hand = self.hand_module(hand)\n",
    "        other = self.other_module(other)\n",
    "        h = hand + other\n",
    "        for n in range(self.n_recyile):\n",
    "            h = self.line1(h)\n",
    "        for n in range(self.n_recyile):\n",
    "            h = self.line2(h)\n",
    "        for n in range(self.n_recyile):\n",
    "            h = self.line3(h)\n",
    "        h = self.end(h)\n",
    "        return h\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "class BackboneFixedLen(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_dim=42,\n",
    "                 dim1=128,\n",
    "                 dim2=512,\n",
    "                 kernel_size=3, padding=1,\n",
    "                 negative_slope=0.1,\n",
    "                 ):\n",
    "        super(BackboneFixedLen, self).__init__()\n",
    "        self.actf = torch.nn.LeakyReLU(negative_slope=negative_slope)\n",
    "        self.bn0 = nn.BatchNorm1d(in_dim)\n",
    "        self.conv1 = nn.Conv1d(in_dim, dim1, kernel_size=3, padding=1, bias=True)\n",
    "        self.conv2 = RSUnit1D(dim1, kernel_size=kernel_size, padding=padding, actf=self.actf)\n",
    "        self.conv3 = RSUnit1D(dim1, kernel_size=kernel_size, padding=padding, actf=self.actf)\n",
    "        self.conv4 = RSUnit1D(dim1, kernel_size=kernel_size, padding=padding, actf=self.actf)\n",
    "        self.conv5 = RSUnit1D(dim1, kernel_size=kernel_size, padding=padding, actf=self.actf)\n",
    "        self.conv6 = RSUnit1D(dim1, kernel_size=kernel_size, padding=padding, actf=self.actf)\n",
    "        self.conv6a = nn.Conv1d(dim1, dim2, kernel_size=1, padding=0, bias=True)\n",
    "\n",
    "        self.flatten = torch.nn.Flatten(1)\n",
    "        self.g_pool = torch.nn.AdaptiveMaxPool1d(1, return_indices=False)\n",
    "        self.pool = torch.nn.MaxPool1d(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.bn0(x)\n",
    "        h = self.conv1(h)\n",
    "        h = self.conv2(h)\n",
    "        h = self.pool(h)\n",
    "        h = self.conv3(h)\n",
    "        h = self.pool(h)\n",
    "        h = self.conv4(h)\n",
    "        h = self.pool(h)\n",
    "        h = self.conv5(h)\n",
    "        h = self.conv6(h)\n",
    "        h = self.conv6a(h)\n",
    "        h = self.g_pool(h)\n",
    "        h = self.flatten(h)\n",
    "        return h\n",
    "\n",
    "\n",
    "class ModelFixedLen(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_dim_H=42,\n",
    "                 in_dim_L=80,\n",
    "                 dim1_H=128,\n",
    "                 dim1_L=64,\n",
    "                 dim2=512,\n",
    "                 n_class=250,\n",
    "                 kernel_size=3, padding=1,\n",
    "                 arc_m=0.5,\n",
    "                 arc_s=15,\n",
    "                 easy_margin=False,\n",
    "                 stochastic_depth_prob=0.0,\n",
    "                 negative_slope=0.1,\n",
    "                 n_recyile=1\n",
    "                 ):\n",
    "        super(ModelFixedLen, self).__init__()\n",
    "        self.actf = torch.nn.LeakyReLU(negative_slope=negative_slope)\n",
    "        self.hand_module = BackboneFixedLen(in_dim=in_dim_H, dim1=dim1_H, dim2=dim2, negative_slope=negative_slope)\n",
    "        self.other_module = BackboneFixedLen(in_dim=in_dim_L, dim1=dim1_L, dim2=dim2, negative_slope=negative_slope)\n",
    "\n",
    "        self.line1 = LRUnit1D(dim2, stochastic_depth_prob, actf=self.actf)\n",
    "        self.line2 = LRUnit1D(dim2, stochastic_depth_prob, actf=self.actf)\n",
    "        self.line3 = LRUnit1D(dim2, stochastic_depth_prob, actf=self.actf)\n",
    "        self.end = ArcMarginProduct(dim2, n_class, easy_margin=easy_margin, s=arc_s, m=arc_m)\n",
    "        self.flatten = torch.nn.Flatten(1)\n",
    "        self.g_pool = torch.nn.AdaptiveMaxPool1d(1, return_indices=False)\n",
    "        self.pool = torch.nn.MaxPool1d(2)\n",
    "\n",
    "        self.n_recyile = n_recyile\n",
    "\n",
    "    def forward(self, hand, other):\n",
    "        hand = self.hand_module(hand)\n",
    "        other = self.other_module(other)\n",
    "        h = hand + other\n",
    "        for n in range(self.n_recyile):\n",
    "            h = self.line1(h)\n",
    "        for n in range(self.n_recyile):\n",
    "            h = self.line2(h)\n",
    "        for n in range(self.n_recyile):\n",
    "            h = self.line3(h)\n",
    "        h = self.end(h)\n",
    "        return h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fbf28d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T15:03:52.131548Z",
     "iopub.status.busy": "2023-05-05T15:03:52.131167Z",
     "iopub.status.idle": "2023-05-05T15:03:52.211618Z",
     "shell.execute_reply": "2023-05-05T15:03:52.210498Z"
    },
    "papermill": {
     "duration": 0.090397,
     "end_time": "2023-05-05T15:03:52.214215",
     "exception": false,
     "start_time": "2023-05-05T15:03:52.123818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "@torch.jit.script\n",
    "def normalize_by_midwayBetweenEyes(x):\n",
    "\n",
    "    midwayBetweenEyes = x[:, 168]\n",
    "    mask = ~torch.isnan(midwayBetweenEyes[:, 0])\n",
    "    masked = midwayBetweenEyes[mask]  # .mean(keepdims=True)\n",
    "    m = torch.mean(masked, dim=0)\n",
    "    if torch.any(torch.isnan(m)): \n",
    "        return x\n",
    "    else:\n",
    "        m = torch.unsqueeze(m, 0)\n",
    "        m = torch.unsqueeze(m, 0)\n",
    "    return x - m\n",
    "\n",
    "\n",
    "@torch.jit.script\n",
    "def apply_hand_mask(x):\n",
    "\n",
    "    hand_mask = ~torch.isnan(x[:, 0, 0])\n",
    "    m = x[~torch.isnan(x)].mean(0)  # noramlisation to common maen\n",
    "    m = torch.unsqueeze(m, 0)\n",
    "    m = torch.unsqueeze(m, 0)\n",
    "    x = x - m\n",
    "    s = x[~torch.isnan(x)].std(0)\n",
    "    s = torch.unsqueeze(s, 0)\n",
    "    s = torch.unsqueeze(s, 0)\n",
    "    x = x / s\n",
    "    x = torch.where(torch.isnan(x), torch.tensor(0.0, dtype=torch.float32), x)\n",
    "\n",
    "    if hand_mask.sum() > 0:\n",
    "        hand = x[hand_mask, :21]\n",
    "    else:\n",
    "        hand = x[:, :21]\n",
    "    other = x[:, 21:]\n",
    "    return hand, other\n",
    "\n",
    "\n",
    "@torch.jit.script\n",
    "def apply_autoflip(xy):\n",
    "\n",
    "    left_start_index = 468\n",
    "    right_start_index = 522\n",
    "    length = xy[:, 0, 0].shape[0]\n",
    "    l_num = length - torch.isnan(xy[:, left_start_index, 0]).sum()\n",
    "    r_num = length - torch.isnan(xy[:, right_start_index, 0]).sum()\n",
    "\n",
    "    # 左手主体の場合\n",
    "    if r_num < l_num:\n",
    "        xy = torch.stack((-xy[:, :, 0], xy[:, :, 1]), dim=2)\n",
    "\n",
    "        hand_indexes = torch.tensor((468, 469, 470, 471, 472, 473, 474, 475, 476, 477,\n",
    "                                     478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488))\n",
    "\n",
    "        lipsUpperOuter_indexes = torch.tensor((291, 409, 270, 269, 267, 0, 37, 39, 40, 185, 61))\n",
    "        lipsLowerOuter_indexes = torch.tensor((375, 321, 405, 314, 17, 84, 181, 91, 46))\n",
    "        lipsUpperInner_indexes = torch.tensor((308, 415, 310, 311, 312, 13, 82, 81, 80, 191, 78))\n",
    "        lipsLowerInner_indexes = torch.tensor((324, 318, 402, 317, 14, 87, 178, 88, 95))\n",
    "\n",
    "    else:\n",
    "\n",
    "        hand_indexes = torch.tensor((522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534,\n",
    "                                     535, 536, 537, 538, 539, 540, 541, 542))\n",
    "\n",
    "        lipsUpperOuter_indexes = torch.tensor((61, 185, 40, 39, 37, 0, 267, 269, 270, 409, 291))\n",
    "        lipsLowerOuter_indexes = torch.tensor((46, 91, 181, 84, 17, 314, 405, 321, 375))\n",
    "        lipsUpperInner_indexes = torch.tensor((78, 191, 80, 81, 82, 13, 312, 311, 310, 415, 308))\n",
    "        lipsLowerInner_indexes = torch.tensor((95, 88, 178, 87, 14, 317, 402, 318, 324))\n",
    "\n",
    "    # l_hand = xy[:, l_hand_indexes]\n",
    "    hand = xy[:, hand_indexes]\n",
    "\n",
    "    lipsUpperOuter = xy[:, lipsUpperOuter_indexes]\n",
    "    lipsLowerOuter = xy[:, lipsLowerOuter_indexes]\n",
    "    lipsUpperInner = xy[:, lipsUpperInner_indexes]\n",
    "    lipsLowerInner = xy[:, lipsLowerInner_indexes]\n",
    "\n",
    "    x = torch.concat((hand,\n",
    "                      lipsUpperOuter,\n",
    "                      lipsLowerOuter,\n",
    "                      lipsUpperInner,\n",
    "                      lipsLowerInner), dim=1)\n",
    "    print(\"feature\", x.shape)\n",
    "    return x\n",
    "\n",
    "\n",
    "class AslData_tf(nn.Module):\n",
    "\n",
    "    def __init__(self, seq_length):\n",
    "        super(AslData_tf, self).__init__()\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "    def forward(self, data):\n",
    "        # TxDx3\n",
    "        # print(x.shape)\n",
    "\n",
    "        xy = data[:, :, :2]  # TxDx2\n",
    "        xy = normalize_by_midwayBetweenEyes(xy)\n",
    "\n",
    "        # x = x[:, self.indexes]  # Txdx2\n",
    "        xy = apply_autoflip(xy)\n",
    "\n",
    "        hand, other = apply_hand_mask(xy)\n",
    "\n",
    "        hand = torch.reshape(hand, (hand.shape[0], -1))  # T , 2*d\n",
    "        hand = torch.permute(hand, (1, 0))  # 2*d, T\n",
    "        print(hand.shape)\n",
    "        other = torch.reshape(other, (other.shape[0], -1))  # T , 2*d\n",
    "        other = torch.permute(other, (1, 0))  # 2*d, T\n",
    "        print(other.shape)\n",
    "\n",
    "        hand = torch.unsqueeze(hand, 0)\n",
    "        other = torch.unsqueeze(other, 0)\n",
    "\n",
    "        hand_fixed_len = torch.unsqueeze(hand, 0)\n",
    "        hand_fixed_len = torch.nn.functional.interpolate(hand_fixed_len, size=(hand_fixed_len.shape[2], self.seq_length))\n",
    "        hand_fixed_len = hand_fixed_len[0]\n",
    "\n",
    "        other_fixed_len = torch.unsqueeze(other, 0)\n",
    "        other_fixed_len = torch.nn.functional.interpolate(other_fixed_len, size=(other_fixed_len.shape[2], self.seq_length))\n",
    "        other_fixed_len = other_fixed_len[0]\n",
    "\n",
    "        # Since the batch size is 1 during inference,\n",
    "        # there is no need for padding, but only 5 padding is used to match during learning.\n",
    "        hand_variable_len = torch.nn.ConstantPad1d((0, 5), 0)(hand)\n",
    "        other_variable_len = torch.nn.ConstantPad1d((0, 5), 0)(other)\n",
    "\n",
    "        print(\"hand_fixed_len\", hand_fixed_len.shape)\n",
    "        print(\"other_fixed_len\", other_fixed_len.shape)\n",
    "        print(\"hand_variable_len\", hand_variable_len.shape)\n",
    "        print(\"other_variable_len\", other_variable_len.shape)\n",
    "        return hand_fixed_len, other_fixed_len, hand_variable_len, other_variable_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1aec91ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T15:03:52.229621Z",
     "iopub.status.busy": "2023-05-05T15:03:52.228814Z",
     "iopub.status.idle": "2023-05-05T15:03:52.238619Z",
     "shell.execute_reply": "2023-05-05T15:03:52.237464Z"
    },
    "papermill": {
     "duration": 0.019223,
     "end_time": "2023-05-05T15:03:52.241029",
     "exception": false,
     "start_time": "2023-05-05T15:03:52.221806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class SubmitModel(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 ):\n",
    "        \n",
    "        super(SubmitModel, self).__init__()\n",
    "        self.prepare = AslData_tf(SEQ_LEN)\n",
    "        self.fix_len_models = nn.ModuleList()\n",
    "        self.var_len_models = nn.ModuleList()\n",
    "\n",
    "    def __call__(self, x):\n",
    "        \n",
    "        hand_fixed_len, other_fixed_len, hand_variable_len, other_variable_len = self.prepare(x)\n",
    "        print(len(self.fix_len_models), len(self.var_len_models))\n",
    "\n",
    "        ys = []\n",
    "        for i in range(len(self.fix_len_models)):\n",
    "            ys.append((self.fix_len_models[i](hand_fixed_len, other_fixed_len)))\n",
    "        for i in range(len(self.var_len_models)):\n",
    "            ys.append((self.var_len_models[i](hand_variable_len, other_variable_len)))\n",
    "        y = torch.cat(ys, dim=0).mean(dim=0)\n",
    "        return y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07ad14b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T15:03:52.254333Z",
     "iopub.status.busy": "2023-05-05T15:03:52.253859Z",
     "iopub.status.idle": "2023-05-05T15:03:52.263037Z",
     "shell.execute_reply": "2023-05-05T15:03:52.261741Z"
    },
    "papermill": {
     "duration": 0.018989,
     "end_time": "2023-05-05T15:03:52.265575",
     "exception": false,
     "start_time": "2023-05-05T15:03:52.246586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_relevant_data_subset(pq_path):\n",
    "    #定义三个列，xyz维度\n",
    "    data_columns = ['x', 'y', 'z']\n",
    "    #从给定路径，指定列读出df\n",
    "    data = pd.read_parquet(pq_path, columns=data_columns)\n",
    "    #计算数据中有多少个帧\n",
    "    n_frames = int(len(data) / ROWS_PER_FRAME)\n",
    "    #转换矩阵行数和列数，变成n_frames页，ROWS_PER_FRAME行，3列的三维矩阵\n",
    "    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n",
    "    #把data里面的数据都转换成np.float32格式\n",
    "    return data.astype(np.float32)\n",
    "\n",
    "DATA_PATH = \"../data/\"\n",
    "INPUT_PATH = \"../input/asl-signs/\"\n",
    "LANDMARK_FILES_DIR = os.path.join(INPUT_PATH, \"train_landmark_files\")\n",
    "TRAIN_FILE = os.path.join(INPUT_PATH, \"train.csv\")\n",
    "JSON_FILE = os.path.join(INPUT_PATH, \"sign_to_prediction_index_map.json\")\n",
    "\n",
    "n_class = 250\n",
    "#每一帧的像素行数？关节点数\n",
    "ROWS_PER_FRAME = 543\n",
    "\n",
    "SEQ_LEN = 96\n",
    "arc_s = 47\n",
    "arc_m = 0.0\n",
    "easy_margin = True\n",
    "negative_slope = 0.1\n",
    "\n",
    "in_dim_H = 42\n",
    "in_dim_L = 80\n",
    "dim1_H = 128\n",
    "dim1_L = 64\n",
    "dim2 = 512\n",
    "opset_version=12\n",
    "\n",
    "result_path = \"/kaggle/input/asl-4th-place-model/ASL_4th_place_model/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42fa669f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T15:03:52.279154Z",
     "iopub.status.busy": "2023-05-05T15:03:52.278702Z",
     "iopub.status.idle": "2023-05-05T15:03:53.316446Z",
     "shell.execute_reply": "2023-05-05T15:03:53.314877Z"
    },
    "papermill": {
     "duration": 1.048059,
     "end_time": "2023-05-05T15:03:53.319437",
     "exception": false,
     "start_time": "2023-05-05T15:03:52.271378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): ModelVariableLen(\n",
       "    (actf): LeakyReLU(negative_slope=0.1)\n",
       "    (hand_module): BackboneVariableLen(\n",
       "      (actf): LeakyReLU(negative_slope=0.1)\n",
       "      (bn0): BatchNorm1d(42, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv1d(42, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv2): RSUnit1D(\n",
       "        (layer0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (bn0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (layer1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (actf): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "      (conv3): RSUnit1D(\n",
       "        (layer0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (bn0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (layer1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (actf): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "      (conv4): RSUnit1D(\n",
       "        (layer0): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (bn0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (layer1): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (actf): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "      (conv5): RSUnit1D(\n",
       "        (layer0): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (bn0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (layer1): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (actf): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "      (conv6): RSUnit1D(\n",
       "        (layer0): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (bn0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (layer1): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (actf): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "      (conv6a): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "      (g_pool): AdaptiveMaxPool1d(output_size=1)\n",
       "      (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (other_module): BackboneVariableLen(\n",
       "      (actf): LeakyReLU(negative_slope=0.1)\n",
       "      (bn0): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv1d(80, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv2): RSUnit1D(\n",
       "        (layer0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (bn0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (layer1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (actf): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "      (conv3): RSUnit1D(\n",
       "        (layer0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (bn0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (layer1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (actf): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "      (conv4): RSUnit1D(\n",
       "        (layer0): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (bn0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (layer1): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (actf): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "      (conv5): RSUnit1D(\n",
       "        (layer0): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (bn0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (layer1): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (actf): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "      (conv6): RSUnit1D(\n",
       "        (layer0): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (bn0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (layer1): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (actf): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "      (conv6a): Conv1d(64, 512, kernel_size=(1,), stride=(1,))\n",
       "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "      (g_pool): AdaptiveMaxPool1d(output_size=1)\n",
       "      (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (line1): LRUnit1D(\n",
       "      (layer0): Linear(in_features=512, out_features=512, bias=False)\n",
       "      (bn0): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (layer1): Linear(in_features=512, out_features=512, bias=False)\n",
       "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (actf): LeakyReLU(negative_slope=0.1)\n",
       "      (stochastic_depth): StochasticDepth(p=0.5, mode=row)\n",
       "    )\n",
       "    (line2): LRUnit1D(\n",
       "      (layer0): Linear(in_features=512, out_features=512, bias=False)\n",
       "      (bn0): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (layer1): Linear(in_features=512, out_features=512, bias=False)\n",
       "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (actf): LeakyReLU(negative_slope=0.1)\n",
       "      (stochastic_depth): StochasticDepth(p=0.5, mode=row)\n",
       "    )\n",
       "    (line3): LRUnit1D(\n",
       "      (layer0): Linear(in_features=512, out_features=512, bias=False)\n",
       "      (bn0): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (layer1): Linear(in_features=512, out_features=512, bias=False)\n",
       "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (actf): LeakyReLU(negative_slope=0.1)\n",
       "      (stochastic_depth): StochasticDepth(p=0.5, mode=row)\n",
       "    )\n",
       "    (end): ArcMarginProduct()\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (g_pool): AdaptiveMaxPool1d(output_size=1)\n",
       "    (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (1): ModelVariableLen(\n",
       "    (actf): LeakyReLU(negative_slope=0.1)\n",
       "    (hand_module): BackboneVariableLen(\n",
       "      (actf): LeakyReLU(negative_slope=0.1)\n",
       "      (bn0): BatchNorm1d(42, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv1d(42, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv2): RSUnit1D(\n",
       "        (layer0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (bn0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (layer1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (actf): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "      (conv3): RSUnit1D(\n",
       "        (layer0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (bn0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (layer1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (actf): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "      (conv4): RSUnit1D(\n",
       "        (layer0): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (bn0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (layer1): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (actf): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "      (conv5): RSUnit1D(\n",
       "        (layer0): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (bn0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (layer1): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (actf): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "      (conv6): RSUnit1D(\n",
       "        (layer0): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (bn0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (layer1): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (actf): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "      (conv6a): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "      (g_pool): AdaptiveMaxPool1d(output_size=1)\n",
       "      (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (other_module): BackboneVariableLen(\n",
       "      (actf): LeakyReLU(negative_slope=0.1)\n",
       "      (bn0): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv1d(80, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv2): RSUnit1D(\n",
       "        (layer0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (bn0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (layer1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (actf): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "      (conv3): RSUnit1D(\n",
       "        (layer0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (bn0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (layer1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (actf): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "      (conv4): RSUnit1D(\n",
       "        (layer0): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (bn0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (layer1): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (actf): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "      (conv5): RSUnit1D(\n",
       "        (layer0): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (bn0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (layer1): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (actf): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "      (conv6): RSUnit1D(\n",
       "        (layer0): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (bn0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (layer1): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (actf): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "      (conv6a): Conv1d(64, 512, kernel_size=(1,), stride=(1,))\n",
       "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "      (g_pool): AdaptiveMaxPool1d(output_size=1)\n",
       "      (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (line1): LRUnit1D(\n",
       "      (layer0): Linear(in_features=512, out_features=512, bias=False)\n",
       "      (bn0): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (layer1): Linear(in_features=512, out_features=512, bias=False)\n",
       "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (actf): LeakyReLU(negative_slope=0.1)\n",
       "      (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "    )\n",
       "    (line2): LRUnit1D(\n",
       "      (layer0): Linear(in_features=512, out_features=512, bias=False)\n",
       "      (bn0): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (layer1): Linear(in_features=512, out_features=512, bias=False)\n",
       "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (actf): LeakyReLU(negative_slope=0.1)\n",
       "      (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "    )\n",
       "    (line3): LRUnit1D(\n",
       "      (layer0): Linear(in_features=512, out_features=512, bias=False)\n",
       "      (bn0): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (layer1): Linear(in_features=512, out_features=512, bias=False)\n",
       "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (actf): LeakyReLU(negative_slope=0.1)\n",
       "      (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "    )\n",
       "    (end): ArcMarginProduct()\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (g_pool): AdaptiveMaxPool1d(output_size=1)\n",
       "    (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SubmitModel()\n",
    "\n",
    "model_path = os.path.join(result_path, \"ModelFixedLen_deep_seed0_cleanlab_False\", \"swa_300.pt\")\n",
    "tmp_model = ModelFixedLen(in_dim_H=in_dim_H,\n",
    "                          in_dim_L=in_dim_L,\n",
    "                          dim1_H=dim1_H,\n",
    "                          dim1_L=dim1_L,\n",
    "                          dim2=dim2,\n",
    "                          easy_margin=easy_margin,\n",
    "                          arc_s=arc_s, arc_m=arc_m,\n",
    "                          stochastic_depth_prob=0.5,\n",
    "                          negative_slope=negative_slope,\n",
    "                          n_recyile=3\n",
    "                          )\n",
    "swa_model = torch.optim.swa_utils.AveragedModel(tmp_model)\n",
    "swa_model.module.eval()\n",
    "swa_model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
    "model.fix_len_models.append(swa_model.module)\n",
    "\"\"\"\n",
    "model_path = os.path.join(result_path, \"ModelFixedLen_deep_seed5_cleanlab_True\", \"swa_300.pt\")\n",
    "tmp_model = ModelFixedLen(in_dim_H=in_dim_H,\n",
    "                          in_dim_L=in_dim_L,\n",
    "                          dim1_H=dim1_H,\n",
    "                          dim1_L=dim1_L,\n",
    "                          dim2=dim2,\n",
    "                          easy_margin=easy_margin,\n",
    "                          arc_s=arc_s, arc_m=arc_m,\n",
    "                          stochastic_depth_prob=0.5,\n",
    "                          negative_slope=negative_slope,\n",
    "                          n_recyile=3\n",
    "                          )\n",
    "swa_model = torch.optim.swa_utils.AveragedModel(tmp_model)\n",
    "swa_model.module.eval()\n",
    "swa_model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
    "model.fix_len_models.append(swa_model.module)\n",
    "\"\"\"\n",
    "# %%\n",
    "model_path = os.path.join(result_path, \"ModelFixedLen_deep_seed6_cleanlab_True\", \"swa_300.pt\")\n",
    "tmp_model = ModelFixedLen(in_dim_H=in_dim_H,\n",
    "                          in_dim_L=in_dim_L,\n",
    "                          dim1_H=dim1_H,\n",
    "                          dim1_L=dim1_L,\n",
    "                          dim2=dim2,\n",
    "                          easy_margin=easy_margin,\n",
    "                          arc_s=arc_s, arc_m=arc_m,\n",
    "                          stochastic_depth_prob=0.5,\n",
    "                          negative_slope=negative_slope,\n",
    "                          n_recyile=3\n",
    "                          )\n",
    "swa_model = torch.optim.swa_utils.AveragedModel(tmp_model)\n",
    "swa_model.module.eval()\n",
    "swa_model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
    "model.fix_len_models.append(swa_model.module)\n",
    "# %%\n",
    "model_path = os.path.join(result_path, \"ModelFixedLen_shallow_seed5_cleanlab_False\", \"swa_300.pt\")\n",
    "tmp_model = ModelFixedLen(in_dim_H=in_dim_H,\n",
    "                          in_dim_L=in_dim_L,\n",
    "                          dim1_H=dim1_H,\n",
    "                          dim1_L=dim1_L,\n",
    "                          dim2=dim2,\n",
    "                          easy_margin=easy_margin,\n",
    "                          arc_s=arc_s, arc_m=arc_m,\n",
    "                          stochastic_depth_prob=0.1,\n",
    "                          negative_slope=negative_slope,\n",
    "                          n_recyile=1\n",
    "                          )\n",
    "swa_model = torch.optim.swa_utils.AveragedModel(tmp_model)\n",
    "swa_model.module.eval()\n",
    "swa_model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
    "model.fix_len_models.append(swa_model.module)\n",
    "\n",
    "# %%\n",
    "model_path = os.path.join(result_path, \"ModelVariableLen_deep_seed35_cleanlab_True\", \"swa_300.pt\")\n",
    "tmp_model = ModelVariableLen(in_dim_H=in_dim_H, in_dim_L=in_dim_L,\n",
    "                             dim1_H=dim1_H,\n",
    "                             dim1_L=dim1_L,\n",
    "                             dim2=dim2,\n",
    "                             easy_margin=easy_margin,\n",
    "                             arc_s=arc_s, arc_m=arc_m,\n",
    "                             stochastic_depth_prob=0.5,\n",
    "                             negative_slope=negative_slope,\n",
    "                             n_recyile=3\n",
    "                             )\n",
    "swa_model = torch.optim.swa_utils.AveragedModel(tmp_model)\n",
    "swa_model.module.eval()\n",
    "swa_model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
    "model.var_len_models.append(swa_model.module)\n",
    "\n",
    "# %%\n",
    "model_path = os.path.join(result_path, \"ModelVariableLen_shallow_seed150_cleanlab_False\", \"swa_300.pt\")\n",
    "tmp_model = ModelVariableLen(in_dim_H=in_dim_H, in_dim_L=in_dim_L,\n",
    "                             dim1_H=dim1_H,\n",
    "                             dim1_L=dim1_L,\n",
    "                             dim2=dim2,\n",
    "                             easy_margin=easy_margin,\n",
    "                             arc_s=arc_s, arc_m=arc_m,\n",
    "                             stochastic_depth_prob=0.1,\n",
    "                             negative_slope=negative_slope,\n",
    "                             n_recyile=1\n",
    "                             )\n",
    "swa_model = torch.optim.swa_utils.AveragedModel(tmp_model)\n",
    "swa_model.module.eval()\n",
    "swa_model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
    "model.var_len_models.append(swa_model.module)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b0002f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T15:03:53.334035Z",
     "iopub.status.busy": "2023-05-05T15:03:53.333553Z",
     "iopub.status.idle": "2023-05-05T15:03:53.953372Z",
     "shell.execute_reply": "2023-05-05T15:03:53.951907Z"
    },
    "papermill": {
     "duration": 0.630492,
     "end_time": "2023-05-05T15:03:53.956513",
     "exception": false,
     "start_time": "2023-05-05T15:03:53.326021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature [23, 61, 2]\n",
      "torch.Size([42, 11])\n",
      "torch.Size([80, 23])\n",
      "hand_fixed_len torch.Size([1, 42, 96])\n",
      "other_fixed_len torch.Size([1, 80, 96])\n",
      "hand_variable_len torch.Size([1, 42, 16])\n",
      "other_variable_len torch.Size([1, 80, 28])\n",
      "3 2\n",
      "torch.Size([1, 512, 16])\n",
      "torch.Size([1, 512, 11])\n",
      "torch.Size([1, 512, 28])\n",
      "torch.Size([1, 512, 23])\n",
      "torch.Size([1, 512, 16])\n",
      "torch.Size([1, 512, 11])\n",
      "torch.Size([1, 512, 28])\n",
      "torch.Size([1, 512, 23])\n"
     ]
    }
   ],
   "source": [
    "#读train.csv存到一个df里，里面有.Parquet文件路径，以及其中数据的标签\n",
    "df = pd.read_csv(TRAIN_FILE)\n",
    "#读sign_to_prediction_index_map.json，里面有每个标签对应数字的映射\n",
    "label_map = json.load(open(JSON_FILE, \"r\"))\n",
    "#给df加一行lable，里面存的是每一行的标签对应的数字\n",
    "df['label'] = df['sign'].map(label_map)\n",
    "#取出第一行的数据\n",
    "row = df.loc[0]\n",
    "#读第一行path里对应的.Parquet文件，转换成一个帧数*每帧像素行数*xyz三列的数组\n",
    "sample_input = load_relevant_data_subset(os.path.join(INPUT_PATH, row.path))\n",
    "#把np矩阵转换成Tensor格式的矩阵，更适合深度学习训练\n",
    "sample_input = torch.tensor(sample_input)\n",
    "#把处理好的数据放进自定义的model里面\n",
    "a = model(sample_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38e83bd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T15:03:53.970523Z",
     "iopub.status.busy": "2023-05-05T15:03:53.970079Z",
     "iopub.status.idle": "2023-05-05T15:04:00.424794Z",
     "shell.execute_reply": "2023-05-05T15:04:00.423364Z"
    },
    "papermill": {
     "duration": 6.465223,
     "end_time": "2023-05-05T15:04:00.427989",
     "exception": false,
     "start_time": "2023-05-05T15:03:53.962766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([23, 543, 3])\n",
      "feature [23, 61, 2]\n",
      "torch.Size([42, 11])\n",
      "torch.Size([80, 23])\n",
      "hand_fixed_len torch.Size([1, 42, 96])\n",
      "other_fixed_len torch.Size([1, 80, 96])\n",
      "hand_variable_len torch.Size([1, 42, 16])\n",
      "other_variable_len torch.Size([1, 80, 28])\n",
      "3 2\n",
      "torch.Size([1, 512, 16])\n",
      "torch.Size([1, 512, 11])\n",
      "torch.Size([1, 512, 28])\n",
      "torch.Size([1, 512, 23])\n",
      "torch.Size([1, 512, 16])\n",
      "torch.Size([1, 512, 11])\n",
      "torch.Size([1, 512, 28])\n",
      "torch.Size([1, 512, 23])\n"
     ]
    }
   ],
   "source": [
    "models_path = \"/kaggle/working/\"\n",
    "\n",
    "os.makedirs(models_path, exist_ok=True)\n",
    "onnx_feat_gen_path = os.path.join(models_path, 'model.onnx')\n",
    "tf_feat_gen_path = os.path.join(models_path, 'tf_model')\n",
    "tflite_model_path = os.path.join(models_path, 'model.tflite')\n",
    "\n",
    "\n",
    "print(sample_input.shape)\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,                  # PyTorch Model\n",
    "    sample_input,                    # Input tensor\n",
    "    onnx_feat_gen_path,        # Output file (eg. 'output_model.onnx')\n",
    "    opset_version=opset_version,       # Operator support version\n",
    "    input_names=['inputs'],   # Input tensor name (arbitary)\n",
    "    output_names=['outputs'],  # Output tensor name (arbitary)\n",
    "    dynamic_axes={\n",
    "        'inputs': {0: 'inputs',\n",
    "                   1: 'length'},\n",
    "        'outputs': {0: 'inputs'},\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1adf5f44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T15:04:00.443231Z",
     "iopub.status.busy": "2023-05-05T15:04:00.442777Z",
     "iopub.status.idle": "2023-05-05T15:06:49.444159Z",
     "shell.execute_reply": "2023-05-05T15:06:49.443158Z"
    },
    "papermill": {
     "duration": 169.017812,
     "end_time": "2023-05-05T15:06:49.452255",
     "exception": false,
     "start_time": "2023-05-05T15:04:00.434443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting from onnx to tensorflow...\n",
      "converting from tensorflow to tflite\n",
      "converting finish!!\n"
     ]
    }
   ],
   "source": [
    "print(\"converting from onnx to tensorflow...\")\n",
    "onnx_feat_gen = onnx.load(onnx_feat_gen_path)\n",
    "tf_rep = onnx_tf.backend.prepare(onnx_feat_gen)\n",
    "tf_rep.export_graph(tf_feat_gen_path)\n",
    "del tf_rep\n",
    "# %%\n",
    "print(\"converting from tensorflow to tflite\")\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(tf_feat_gen_path)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "tflite_model = converter.convert()\n",
    "# Save the model\n",
    "with open(tflite_model_path, 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "print(\"converting finish!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91bbf8af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T15:06:49.467906Z",
     "iopub.status.busy": "2023-05-05T15:06:49.466761Z",
     "iopub.status.idle": "2023-05-05T15:06:49.479557Z",
     "shell.execute_reply": "2023-05-05T15:06:49.478376Z"
    },
    "papermill": {
     "duration": 0.02387,
     "end_time": "2023-05-05T15:06:49.482606",
     "exception": false,
     "start_time": "2023-05-05T15:06:49.458736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "interpreter = tflite_runtime.interpreter.Interpreter(tflite_model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "found_signatures = list(interpreter.get_signature_list().keys())\n",
    "\n",
    "#%%\n",
    "if False:\n",
    "    prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n",
    "    ok = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        row = df.loc[i]\n",
    "        a = load_relevant_data_subset(os.path.join(INPUT_PATH, row.path))\n",
    "        output = prediction_fn(inputs=a)\n",
    "        z = output[\"outputs\"]\n",
    "        sign = np.argmax(z)\n",
    "        ok.append(row.label == sign)\n",
    "        if len(ok) % 1000 == 0:\n",
    "            print(np.mean(ok))\n",
    "    print(np.mean(ok))\n",
    "    # %%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7998e06b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T15:06:49.498086Z",
     "iopub.status.busy": "2023-05-05T15:06:49.497651Z",
     "iopub.status.idle": "2023-05-05T15:06:51.926821Z",
     "shell.execute_reply": "2023-05-05T15:06:51.925384Z"
    },
    "papermill": {
     "duration": 2.440315,
     "end_time": "2023-05-05T15:06:51.929869",
     "exception": false,
     "start_time": "2023-05-05T15:06:49.489554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: kaggle/working/model.tflite (deflated 9%)\r\n"
     ]
    }
   ],
   "source": [
    "!zip submission.zip $tflite_model_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 233.517377,
   "end_time": "2023-05-05T15:06:54.858298",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-05T15:03:01.340921",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
